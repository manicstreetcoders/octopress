---
layout: post
title: "TF-IDF"
date: 2016-01-15 15:10:14 +0900
comments: true
categories: 
---

"Multiplying TF and IDF therefore favours generally rare words that nevertheless occur often in our pages."

TF-IDF 의 아이디어는 사실 단순하다.

1. 웹페이지 하나를 분석한다고 치자. 분석 목적은 키워드 추출.
2. 가장 많이 등장하는 단어로 키워드를 추출한다면, "the" 나 "a" 같은 관사, 혹은 "and" 같은 전치사가 가장 많이 등장하지 않을까?
3. 절대적인 빈도가 아니라 상대적인 빈도가 더 맞을 것 같은데.
4. "the" 의 경우 거의 모든 웹페이지에 등장할테니 상대적인 중요도는 떨어지지않을까?
5. 얼마나 많은 웹페이지에 등장하느냐를 측정하는 것이 IDF (Inverse Document Frequency)
6. (특정 단어가 포함된 도큐먼트의 수/전체 도큐먼트 수)^(-1)
7. Inverse 를 해주었기때문에 rare 한 단어의 경우 IDF 값이 커진다. (실상황에서는 log 값이 유의미하다고)
8. 하나의 문서에 등장하는 단어 빈도를 그대로 사용하지 말고 IDF 로 보정해주면, heuristic 하게 꽤 유의미한 키워드를 추출할 수 있다고 한다.
9. TF (Term Frequency) * IDF (Inverse Document Frequency) = TF-IDF

그렇다면, AdWords 같은 광고 스킴을 디자인한다고 가정하고. 광고주는 Nike 를 가정하자. 그리고 marathon, race, trophy 가 키워드인 웹페이지가 두 개있다고 가정하는데, 하나는 운동에 관한 페이지고 하나는 선거(election)에 관한 페이지다. 물론 Nike 는 운동에 관한 페이지에 자사 광고를 노출시키고 싶어한다. 맥락을 구별할 필요가 있는 것인데, 이런 경우 TF-IDF 를 이용할 수 있을까?

이용할 수 있다. 두 개의 단어가 같이 출현하는 빈도를 생각해본다. 예를 들어, `marathon` 과 `42 kilometres` 또는 `26 miles` 는 실제 러닝을 다루는 웹페이지들에서 같이 출현했을 것이다. 또한 `election`, `voter`, `ballot` 은 선거를 다루는 글에서 같이 출현했을 것이다.

다음의 계산을 거치면, 모든 pairs of words 에 대한 correlation 이 계산된다.

```
for every page in all web pages on the internet:
    for every pair of words in the page:
        correlation[word_A,word_B] += tf-idf(word_A) * tf-idf(word_B)
```        

즉 `marathon` 과 `42 kilometres` 의 The Internet 에서의 correlation 값이 나오는 것이다. 이런 무지막지한 계산을 하려니 Hadoop 과 MapReduce 부터 만들고 본 것이리라.

위처럼 word-word correlation 을 이용한 semantic 을 분석하는 기법이 Latent Semantic Analysis 의 기본 아이디어라고 한다. LSA-based algorithm 을 이용하여 Topic Analysis 를 할 수가 있는데, 그 예를 들어본다.
